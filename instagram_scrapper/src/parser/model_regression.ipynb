{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Flatten, Conv2D,Dropout,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"../preprocessed/mydataset.hdf5\"\n",
    "NUMBER_OF_CHUNKS = 30\n",
    "PHOTOS_IN_CHUNK = 1000\n",
    "NUMBER_OF_PHOTOS = NUMBER_OF_CHUNKS*PHOTOS_IN_CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(start=0,stop=0.7,batch_size=300,verbose = False):\n",
    "    \n",
    "    assert start<=stop and start >= 0 and stop <= 1 and batch_size<PHOTOS_IN_CHUNK\n",
    "    \n",
    "    batches_in_chunk = int(PHOTOS_IN_CHUNK/batch_size)\n",
    "    start = int(start*(NUMBER_OF_PHOTOS))\n",
    "    end = int(stop*(NUMBER_OF_PHOTOS))\n",
    "    counter = start\n",
    "    while True:\n",
    "        container = int(counter/PHOTOS_IN_CHUNK)\n",
    "        _from = counter%PHOTOS_IN_CHUNK\n",
    "        _to = _from + batch_size\n",
    "        excess = max(0,_from+batch_size-PHOTOS_IN_CHUNK)\n",
    "        with h5py.File(INPUT_PATH,\"r\") as f:\n",
    "            X = f[\"data\"][str(container)][_from:_to]/255\n",
    "            Y = f[\"labels\"][str(container)][_from:_to]\n",
    "        if _to < end:\n",
    "            with h5py.File(INPUT_PATH,\"r\") as f:\n",
    "                X = np.concatenate([X,f[\"data\"][str((container+1)%NUMBER_OF_CHUNKS)][0:excess]/255],axis=0)\n",
    "                Y = np.concatenate([Y,f[\"labels\"][str((container+1)%NUMBER_OF_CHUNKS)][0:excess]],axis=0)\n",
    "        counter += batch_size\n",
    "        if counter >= end:\n",
    "            counter = start\n",
    "        yield X,Y\n",
    "        if verbose == True:\n",
    "            print(\"Generated X of shape {} and Y of shape: {} from container [\\\"{}\\\"][{}:{}] and container [\\\"{}\\\"][0:{}].\"\n",
    "                  .format(X.shape,Y.shape,container,_from,min(PHOTOS_IN_CHUNK,_to),container+1,excess))\n",
    "        del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "batch_size = 32\n",
    "train_size = 0.9\n",
    "validation_size = 0.05\n",
    "test_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_generator(start = 0,stop=train_size,batch_size=batch_size)\n",
    "validation_generator = create_generator(start = train_size,stop=train_size+validation_size,batch_size=batch_size)\n",
    "test_generator = create_generator(start = train_size+validation_size,stop=min(1,train_size+validation_size+test_size),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"First model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 222, 222, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 111, 111, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 54, 54, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               22151680  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 22,291,617\n",
      "Trainable params: 22,291,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name= \"First model\")\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.summary()\n",
    "optimizer = Adam()\n",
    "#model.compile(optimizer=optimizer, loss='mse')\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer=optimizer, metrics=['mse'])\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 1804s 10s/step - loss: 25.9494 - val_loss: 22.8203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f323561dc50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=int(NUMBER_OF_PHOTOS*train_size/batch_size),\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=int(NUMBER_OF_PHOTOS*validation_size/batch_size), epochs = 1,callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 118s 3s/step - loss: 0.1244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12438814609271029"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = create_generator(start = train_size+validation_size,stop=min(1,train_size+validation_size+test_size),batch_size=batch_size)\n",
    "model.evaluate(test_generator,steps = int(NUMBER_OF_PHOTOS*test_size/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = create_generator(start = train_size+validation_size,stop=min(1,train_size+validation_size+test_size),batch_size=batch_size)\n",
    "Y_pred = model.predict(test_generator,steps = int(NUMBER_OF_PHOTOS*test_size/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014519346"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8137807"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclussion</h1>\n",
    "<p> <h4> Because ratios are distributed with very low standard deviation (30% of mean) our model misrepresent reality and finds one value that gives him the smallest error over all examples and sticks to it. Therefore, prediction has microscopic standard deviation (0.75 % of mean). Perhaps the solution is to use some techniques to discretize our dataset into equally distributed set of classes.</h4> </p> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
