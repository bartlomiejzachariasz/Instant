{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Flatten, Conv2D,Dropout,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"../preprocessed/mydataset.hdf5\"\n",
    "NUMBER_OF_CHUNKS = 30\n",
    "PHOTOS_IN_CHUNK = 1000\n",
    "NUMBER_OF_PHOTOS = NUMBER_OF_CHUNKS*PHOTOS_IN_CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(start=0,stop=0.7,batch_size=300,verbose = False):\n",
    "    \n",
    "    assert start<=stop and start >= 0 and stop <= 1 and batch_size<PHOTOS_IN_CHUNK\n",
    "    \n",
    "    batches_in_chunk = int(PHOTOS_IN_CHUNK/batch_size)\n",
    "    start = int(start*(NUMBER_OF_PHOTOS))\n",
    "    end = int(stop*(NUMBER_OF_PHOTOS))\n",
    "    counter = start\n",
    "    while True:\n",
    "        container = int(counter/PHOTOS_IN_CHUNK)\n",
    "        _from = counter%PHOTOS_IN_CHUNK\n",
    "        _to = _from + batch_size\n",
    "        excess = max(0,_from+batch_size-PHOTOS_IN_CHUNK)\n",
    "        with h5py.File(INPUT_PATH,\"r\") as f:\n",
    "            X = f[\"data\"][str(container)][_from:_to]/255\n",
    "            Y = f[\"labels\"][str(container)][_from:_to]\n",
    "        if _to < end:\n",
    "            with h5py.File(INPUT_PATH,\"r\") as f:\n",
    "                X = np.concatenate([X,f[\"data\"][str((container+1)%NUMBER_OF_CHUNKS)][0:excess]/255],axis=0)\n",
    "                Y = np.concatenate([Y,f[\"labels\"][str((container+1)%NUMBER_OF_CHUNKS)][0:excess]],axis=0)\n",
    "        counter += batch_size\n",
    "        if counter >= end:\n",
    "            counter = start\n",
    "        yield X,Y\n",
    "        if verbose == True:\n",
    "            print(\"Generated X of shape {} and Y of shape: {} from container [\\\"{}\\\"][{}:{}] and container [\\\"{}\\\"][0:{}].\"\n",
    "                  .format(X.shape,Y.shape,container,_from,min(PHOTOS_IN_CHUNK,_to),container+1,excess))\n",
    "        del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "batch_size = 32\n",
    "train_size = 0.2\n",
    "validation_size = 0.05\n",
    "test_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_generator(start = 0,stop=train_size,batch_size=batch_size)\n",
    "validation_generator = create_generator(start = train_size,stop=train_size+validation_size,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = create_generator(start = train_size+validation_size,stop=min(1,train_size+validation_size+test_size),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"First model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 111, 111, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 54, 54, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               22151680  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 22,291,617\n",
      "Trainable params: 22,291,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name= \"First model\")\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer=optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 2074s 11s/step - loss: 0.1142 - val_loss: 0.1071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2df59b87f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=int(NUMBER_OF_PHOTOS*train_size/batch_size),\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=int(NUMBER_OF_PHOTOS*validation_size/batch_size), epochs = 1,callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 118s 3s/step - loss: 0.1244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12438814609271029"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = create_generator(start = train_size+validation_size,stop=min(1,train_size+validation_size+test_size),batch_size=batch_size)\n",
    "model.evaluate(test_generator,steps = int(NUMBER_OF_PHOTOS*test_size/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9349745 ],\n",
       "       [0.9381377 ],\n",
       "       [0.9360941 ],\n",
       "       ...,\n",
       "       [0.93140465],\n",
       "       [0.9275928 ],\n",
       "       [0.9367203 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = create_generator(start = train_size+validation_size,stop=min(1,train_size+validation_size+test_size),batch_size=batch_size)\n",
    "Y_pred = model.predict(test_generator,steps = int(NUMBER_OF_PHOTOS*test_size/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1472, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][500:532] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][532:564] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][564:596] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][596:628] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][628:660] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][660:692] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][692:724] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][724:756] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][756:788] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][788:820] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][820:852] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][852:884] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][884:916] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][916:948] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][948:980] and container [\"8\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"7\"][980:1000] and container [\"8\"][0:12].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][12:44] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][44:76] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][76:108] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][108:140] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][140:172] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][172:204] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][204:236] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][236:268] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][268:300] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][300:332] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][332:364] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][364:396] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][396:428] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][428:460] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][460:492] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][492:524] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][524:556] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][556:588] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][588:620] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][620:652] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][652:684] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][684:716] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][716:748] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][748:780] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][780:812] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][812:844] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][844:876] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][876:908] and container [\"9\"][0:0].\n",
      "Generated X of shape (32, 224, 224, 3) and Y of shape: (32,) from container [\"8\"][908:940] and container [\"9\"][0:0].\n"
     ]
    }
   ],
   "source": [
    "Y = np.ndarray(shape=(0,))\n",
    "steps = int(NUMBER_OF_PHOTOS*test_size/batch_size)\n",
    "for x,y in test_generator:\n",
    "    Y = np.concatenate([Y,y],axis=0)\n",
    "    steps -= 1\n",
    "    if steps == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92975616"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006988769"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0277006567896756"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3387483870983686"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclussion</h1>\n",
    "<p> <h4> Because ratios are distributed with very low standard deviation (30% of mean) our model misrepresent reality and finds one value that gives him the smallest error over all examples and sticks to it. Therefore, prediction has microscopic standard deviation (0.75 % of mean). Perhaps the solution is to use some techniques to discretize our dataset into equally distributed set of classes.</h4> </p> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
