{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Flatten, Conv2D,Dropout,MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import History \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_PHOTOS = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_MB(array):\n",
    "    return int(array.nbytes/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DONT EDIT - VALUES FROM THIS CELL ARE USED LATER IN SOME FUNCTIONS\n",
    "\n",
    "path = \"../input_data/\"\n",
    "photographers = [f for f in os.listdir(path) if f.endswith('.hdf5')]\n",
    "photographers_part = [os.path.getsize(path+photographer) for photographer in photographers]\n",
    "photographers_part = [x/sum(photographers_part) for x in photographers_part]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_generator(start=0.0,end = 0.7,examples_in_chunk = 100):\n",
    "    \n",
    "    assert start >= 0\n",
    "    assert end <= 1\n",
    "    assert start < end\n",
    "    assert examples_in_chunk < 1500\n",
    "    \n",
    "    start = int(start*NUMBER_OF_PHOTOS/examples_in_chunk)\n",
    "    end = int(np.ceil(end*NUMBER_OF_PHOTOS/examples_in_chunk))\n",
    "    for b in range(start,end):\n",
    "        X = np.ndarray(shape = (0,224,224,3))\n",
    "        Y = np.ndarray(shape = (0,))\n",
    "        for i in range (len(photographers)):\n",
    "            if i%3==0:\n",
    "                clear_output()\n",
    "                print(\"Batch: #{}. Progress: {}%\".format(b+1,round(i/len(photographers),2)))\n",
    "            start = round(photographers_part[i]*examples_in_chunk*b)\n",
    "            stop  = start+round(photographers_part[i]*examples_in_chunk)\n",
    "            with h5py.File(\"{}{}\".format(path, photographers[i]),\"r\") as f:\n",
    "                X = np.concatenate([X,f[\"data\"][start:stop]],axis=0)\n",
    "                Y = np.concatenate([Y,f[\"labels\"][start:stop]],axis=0)\n",
    "        yield X/255,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(examples_in_chunk = 1000):\n",
    "    input_path = \"../input_data/\"\n",
    "    output_path = \"../preprocessed/mydataset.hdf5\"\n",
    "    \n",
    "    with h5py.File(output_path, 'a') as f:\n",
    "        f.create_group(\"data\")\n",
    "        f.create_group(\"labels\")\n",
    "        f.create_group(\"scores\")\n",
    "        \n",
    "    finish = int(np.ceil(1*NUMBER_OF_PHOTOS/examples_in_chunk))\n",
    "    for b in range(finish):\n",
    "        X = np.ndarray(dtype = \"int8\", shape = (0,224,224,3))\n",
    "        Y = np.ndarray(shape = (0,))\n",
    "        S = np.ndarray(shape = (0,))\n",
    "        for i in range (len(photographers)):\n",
    "            if i%3==0:\n",
    "                clear_output()\n",
    "                print(\"Batch: #{}. Progress: {}%\".format(b+1,round(i/len(photographers),2)))\n",
    "            start = round(photographers_part[i]*examples_in_chunk*b)\n",
    "            stop  = start+round(photographers_part[i]*examples_in_chunk)\n",
    "            with h5py.File(\"{}{}\".format(input_path, photographers[i]),\"r\") as f:\n",
    "                X = np.concatenate([X,f[\"data\"][start:stop]],axis=0)\n",
    "                Y = np.concatenate([Y,f[\"labels\"][start:stop]],axis=0)\n",
    "                S = np.concatenate([S,f[\"scores\"][start:stop]],axis=0)\n",
    "        with h5py.File(output_path, 'a') as f:\n",
    "            f['data'].create_dataset(\"{}\".format(b),data = X)\n",
    "            f['labels'].create_dataset(\"{}\".format(b),data = Y)\n",
    "            f['scores'].create_dataset(\"{}\".format(b),data = S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"../preprocessed/mydataset.hdf5\",\"r\") as f:\n",
    "    X = f[\"data\"][\"29\"][:]/255\n",
    "    Y = f[\"labels\"][\"29\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data,labels in datasets_generator(start = 0,end=0.05):\n",
    "#     X = data\n",
    "#     Y = labels\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,244,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"First model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 244, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 242, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 121, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 121, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 111, 121, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 109, 119, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 54, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 52, 57, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 46592)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               23855616  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 23,995,553\n",
      "Trainable params: 23,995,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name= \"First model\")\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer=optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: #3. Progress: 0.98%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_size = 0.01\n",
    "validation_size = 0.002\n",
    "\n",
    "train_generator = datasets_generator(start = 0,end=train_size,examples_in_chunk=batch_size)\n",
    "validation_generator = datasets_generator(start = train_size,end=train_size+validation_size,examples_in_chunk=batch_size)\n",
    "test_generator = datasets_generator(start = train_size+validation_size,end=1,examples_in_chunk=batch_size)\n",
    "\n",
    "lol = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=NUMBER_OF_PHOTOS*train_size/batch_size-1,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=NUMBER_OF_PHOTOS*validation_size/batch_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(X_train,Y_train,epochs=5,batch_size=30,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss Curves\n",
    "# plt.figure(figsize=[8,6])\n",
    "# plt.plot(history.history['loss'][1:],'r',linewidth=3.0)\n",
    "# plt.plot(history.history['val_loss'][1:],'b',linewidth=3.0)\n",
    "# plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "# plt.xlabel('Epochs ',fontsize=16)\n",
    "# plt.ylabel('Loss',fontsize=16)\n",
    "# plt.title('Loss Curves',fontsize=16)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
